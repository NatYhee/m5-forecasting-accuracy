{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(f\"/home/npanj/personal_works/m5-forecasting-accuracy\")\n",
    "\n",
    "from src.utils.import_downcasting import import_downcasting\n",
    "from src.utils.plotting import PdfFile\n",
    "from utils import get_wmape, plotting_sales_forecast, get_wmape_custom_groupby\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "root = os.path.join(\n",
    "    \"/home/npanj/personal_works/m5-forecasting-accuracy/assets/data/data_CA_1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data ca1 list columns\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5918109 entries, 0 to 5918108\n",
      "Data columns (total 25 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   date            datetime64[ns]\n",
      " 1   id              category      \n",
      " 2   item_id         category      \n",
      " 3   dept_id         category      \n",
      " 4   cat_id          category      \n",
      " 5   store_id        category      \n",
      " 6   state_id        category      \n",
      " 7   date_code       category      \n",
      " 8   sales           int16         \n",
      " 9   wm_yr_wk        int16         \n",
      " 10  weekday         category      \n",
      " 11  wday            int8          \n",
      " 12  month           int8          \n",
      " 13  year            int16         \n",
      " 14  d               category      \n",
      " 15  event_name_1    category      \n",
      " 16  event_type_1    category      \n",
      " 17  event_name_2    category      \n",
      " 18  event_type_2    category      \n",
      " 19  snap_CA         int8          \n",
      " 20  snap_TX         int8          \n",
      " 21  snap_WI         int8          \n",
      " 22  sell_price      float16       \n",
      " 23  prediction      float16       \n",
      " 24  arima_residual  float16       \n",
      "dtypes: category(13), datetime64[ns](1), float16(3), int16(3), int8(5)\n",
      "memory usage: 237.4 MB\n",
      "None\n",
      "--------------------------------------------------\n",
      "data ca1 score list columns\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3049 entries, 0 to 3048\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   store_id  3049 non-null   category\n",
      " 1   item_id   3049 non-null   category\n",
      " 2   mse       3049 non-null   float16 \n",
      " 3   mae       3049 non-null   float16 \n",
      " 4   sse       3049 non-null   float32 \n",
      "dtypes: category(2), float16(2), float32(1)\n",
      "memory usage: 121.4 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 5918109 entries, 2011-01-29 to 2016-05-22\n",
      "Data columns (total 26 columns):\n",
      " #   Column              Dtype   \n",
      "---  ------              -----   \n",
      " 0   id                  category\n",
      " 1   item_id             category\n",
      " 2   dept_id             category\n",
      " 3   cat_id              category\n",
      " 4   store_id            category\n",
      " 5   state_id            category\n",
      " 6   date_code           category\n",
      " 7   sales               int16   \n",
      " 8   wm_yr_wk            int16   \n",
      " 9   weekday             category\n",
      " 10  wday                int8    \n",
      " 11  month               int8    \n",
      " 12  year                int16   \n",
      " 13  d                   category\n",
      " 14  event_name_1        category\n",
      " 15  event_type_1        category\n",
      " 16  event_name_2        category\n",
      " 17  event_type_2        category\n",
      " 18  snap_CA             int8    \n",
      " 19  snap_TX             int8    \n",
      " 20  snap_WI             int8    \n",
      " 21  sell_price          float16 \n",
      " 22  prediction          float16 \n",
      " 23  arima_residual      float64 \n",
      " 24  event_name_1_group  object  \n",
      " 25  event_type_1_group  object  \n",
      "dtypes: category(13), float16(2), float64(1), int16(3), int8(5), object(2)\n",
      "memory usage: 361.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data_ca1 = import_downcasting(os.path.join(root, \"data_with_arima_resid.csv\"))\n",
    "score_ca1 = import_downcasting(os.path.join(root, \"arima_model_score.csv\"))\n",
    "\n",
    "print(\"data ca1 list columns\")\n",
    "print(data_ca1.info(verbose=True))\n",
    "\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"data ca1 score list columns\")\n",
    "print(score_ca1.info())\n",
    "\n",
    "data_ca1 = data_ca1.set_index(\"date\")\n",
    "data_ca1[\"arima_residual\"] = data_ca1.arima_residual.astype(np.float64)\n",
    "data_ca1[\"event_name_1\"] = (\n",
    "    data_ca1[\"event_name_1\"].cat.add_categories(\"none\").fillna(\"none\")\n",
    ")\n",
    "data_ca1[\"event_type_1\"] = (\n",
    "    data_ca1[\"event_type_1\"].cat.add_categories(\"none\").fillna(\"none\")\n",
    ")\n",
    "\n",
    "data_ca1[\"event_name_1_group\"] = data_ca1[\"event_name_1\"].apply(lambda x: x if x == \"none\" else \"special\" )\n",
    "data_ca1[\"event_type_1_group\"] = data_ca1[\"event_type_1\"].apply(lambda x: x if x == \"none\" else \"special\" )\n",
    "data_ca1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- event\n",
    "  May need to combine between event_1 and event_2\n",
    "\n",
    "- snap\n",
    "  Focus only on snap_CA (CA = Califonia, TX = texas, WI = witcostin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Checking event_name_1 and event_type_1\n",
    "check_event_name_type_1 = data_ca1[[\"event_name_1\", \"event_type_1\", \"sales\"]].groupby([\"event_name_1\", \"event_type_1\"]).count()\\\n",
    ".reset_index()\n",
    "check_event_name_type_1 = check_event_name_type_1[check_event_name_type_1.sales > 0]\n",
    "check_event_name_type_1.sort_values(by=\"event_type_1\", inplace=True)\n",
    "# check_event_name_type_1\n",
    "\n",
    "\n",
    "##### Checking event_name_2 and event_type_2\n",
    "data_ca1.event_name_2.unique()\n",
    "\n",
    "##### Checking snap_CA, snap_TX and snap_WI\n",
    "check_snap = data_ca1[[\"snap_CA\", \"sales\"]].groupby([\"snap_CA\"]).count()\\\n",
    ".reset_index()\n",
    "check_snap.rename(columns={\"sales\": \"num_obs\"}, inplace=True)\n",
    "# check_snap\n",
    "\n",
    "##### Checking snap_CA, snap_TX and snap_WI\n",
    "check_snap = data_ca1[[\"snap_CA\", \"sales\"]].groupby([\"snap_CA\"]).count()\\\n",
    ".reset_index()\n",
    "check_snap.rename(columns={\"sales\": \"num_obs\"}, inplace=True)\n",
    "# check_snap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmape = get_wmape(data_ca1, \"arima_residual\")\n",
    "score_ca1 = pd.merge(\n",
    "    left=score_ca1,\n",
    "    right=wmape[[\"store_id\", \"item_id\", \"wmape\"]],\n",
    "    on=[\"store_id\", \"item_id\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "score_ca1.sort_values(by=\"wmape\", ascending=False, inplace=True)\n",
    "score_ca1[\"rank_pct_wmape\"] = score_ca1[\"wmape\"].rank(pct=True)\n",
    "score_ca1 = score_ca1.reset_index(drop=True)\n",
    "\n",
    "data_ca1[\"root_square_resid\"] = data_ca1[\"arima_residual\"].apply(\n",
    "    lambda x: math.pow(x, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9147 entries, 0 to 9146\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   store_id        9147 non-null   category\n",
      " 1   item_id         9147 non-null   category\n",
      " 2   mse             9147 non-null   float16 \n",
      " 3   mae             9147 non-null   float16 \n",
      " 4   sse             9147 non-null   float32 \n",
      " 5   wmape           9147 non-null   float64 \n",
      " 6   rank_pct_wmape  9147 non-null   float64 \n",
      " 7   cat_id          9147 non-null   category\n",
      "dtypes: category(3), float16(2), float32(1), float64(2)\n",
      "memory usage: 410.2 KB\n"
     ]
    }
   ],
   "source": [
    "item_id_cat_unq = data_ca1.groupby([\"item_id\", \"cat_id\"]).store_id.count().reset_index()\n",
    "score_ca1 = pd.merge(\n",
    "    left=score_ca1,\n",
    "    right=item_id_cat_unq[[\"item_id\", \"cat_id\"]],\n",
    "    left_on=[\"item_id\"],\n",
    "    right_on=[\"item_id\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "score_ca1.info()\n",
    "##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting_sales_forecast(data=data_ca1, score=score_ca1, file_name=\"plotting_store_ca1.pdf\")\n",
    "# plotting_sales_forecast(data=data_ca1, score=score_ca1, file_name=\"plotting_hobbies_ca1.pdf\", product_cat=\"HOBBIES\")\n",
    "# plotting_sales_forecast(data=data_ca1, score=score_ca1, file_name=\"plotting_foods_ca1.pdf\", product_cat=\"FOODS\")\n",
    "# plotting_sales_forecast(data=data_ca1, score=score_ca1, file_name=\"plotting_household_ca1.pdf\",\\\n",
    "#                         product_cat=\"HOUSEHOLD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis WMAPE on event_name_type1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- event_name_1 = \"Christmas\" has sales equal to 0 for all observastion\n",
    "- Marjoriry of data belong to None type\n",
    "- Only these following days that seem to have impact that cuase residual to be higher\n",
    "        Thanksgiving\n",
    "        NewYear\n",
    "        Halloween\n",
    "        LentStart\n",
    "        LentWeek2\n",
    "        ValentinesDay\n",
    "        NBAFinalsStart\n",
    "- grouping into two group comsprised of special and none. These feature seem to have little of impact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmape_by_event_name_1 = get_wmape_custom_groupby(data_ca1, \"arima_residual\", [\"event_name_1\"])\n",
    "wmape_by_event_name_1.sort_values(by=\"wmape\", ascending=False, inplace=True)\n",
    "wmape_by_event_name_1[\"pct_obs\"] = wmape_by_event_name_1[\"num_obs\"]/wmape_by_event_name_1.num_obs.sum()\n",
    "wmape_by_event_name_1.to_csv(\"wmape_analysis/wmape_by_event_name_1.csv\")\n",
    "\n",
    "wmape_event_name_1_grp = get_wmape_custom_groupby(data_ca1, \"arima_residual\", [\"event_name_1_group\"])\n",
    "wmape_event_name_1_grp.to_csv(\"wmape_analysis/wmape_event_name_1_group.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis WMAPE on event_type_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Only these following days that seem to have impact that cuase residual to be higher\n",
    "        National (Highest Different)\n",
    "        Cultural\n",
    "- Grouping to special and non special seem to have none impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmape_by_event_type_1 = get_wmape_custom_groupby(data_ca1, \"arima_residual\", [\"event_type_1\"])\n",
    "wmape_by_event_type_1.sort_values(by=\"wmape\", ascending=False, inplace=True)\n",
    "wmape_by_event_type_1[\"pct_obs\"] = wmape_by_event_type_1[\"num_obs\"]/wmape_by_event_type_1.num_obs.sum()\n",
    "wmape_by_event_type_1.to_csv(\"wmape_analysis/wmape_by_event_type_1.csv\")\n",
    "\n",
    "wmape_by_event_type_1_group = get_wmape_custom_groupby(data_ca1, \"arima_residual\", [\"event_type_1_group\"])\n",
    "wmape_by_event_type_1_group.to_csv(\"wmape_analysis/wmape_by_event_type_1_group.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis WMAPE on snap_CA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- WMAPE seems indifferent between having a snap and not having a snap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmape_snap = get_wmape_custom_groupby(data_ca1, \"arima_residual\", [\"snap_CA\"])\n",
    "wmape_snap.sort_values(by=\"wmape\", ascending=False, inplace=True)\n",
    "wmape_snap[\"pct_obs\"] = wmape_snap[\"num_obs\"]/wmape_snap.num_obs.sum()\n",
    "wmape_snap.to_csv(\"wmape_analysis/wmape_snap.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis WMAPE on DEPARTMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmape_snap = get_wmape_custom_groupby(data_ca1, \"arima_residual\", [\"snap_CA\"])\n",
    "wmape_snap.sort_values(by=\"wmape\", ascending=False, inplace=True)\n",
    "wmape_snap[\"pct_obs\"] = wmape_snap[\"num_obs\"]/wmape_snap.num_obs.sum()\n",
    "wmape_snap.to_csv(\"wmape_analysis/wmape_snap.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis residual from ARIMA model in the group last 20 percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_score_worst_20pct = score_ca1[score_ca1.rank_pct_wmape > 0.8]\n",
    "item_resid_worst_20pct = list(resid_score_worst_20pct.item_id.unique())\n",
    "\n",
    "data_worst_20pct = data_ca1[data_ca1.item_id.isin(item_resid_worst_20pct)]\n",
    "data_worst_20pct.to_csv(os.path.join(root, \"data_arima_worst_30pct.csv\"))\n",
    "\n",
    "data_worst_20pct = import_downcasting(os.path.join(root, \"data_arima_worst_30pct.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Explore event_name_1 and event_type_1</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding from rank in event_name_1 that \"christmas\" event tend to have the most impact on residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_name_1 = (\n",
    "    data_worst_20pct.groupby([\"event_name_1\"]).root_square_resid.mean().reset_index()\n",
    ")\n",
    "event_name_1.rename(columns={\"root_square_resid\": \"mean_rss\"}, inplace=True)\n",
    "event_name_1.sort_values(by=\"mean_rss\", ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "event_type_1 = (\n",
    "    data_worst_20pct.groupby([\"event_type_1\"]).root_square_resid.mean().reset_index()\n",
    ")\n",
    "event_type_1.rename(columns={\"root_square_resid\": \"mean_rss\"}, inplace=True)\n",
    "event_type_1.sort_values(by=\"mean_rss\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>mean_rss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Eid al-Fitr</td>\n",
       "      <td>0.332275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mother's day</td>\n",
       "      <td>0.300049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>VeteransDay</td>\n",
       "      <td>0.298584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>none</td>\n",
       "      <td>0.291260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>OrthodoxEaster</td>\n",
       "      <td>0.288574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LaborDay</td>\n",
       "      <td>0.258789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EidAlAdha</td>\n",
       "      <td>0.256348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NBAFinalsEnd</td>\n",
       "      <td>0.244995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Purim End</td>\n",
       "      <td>0.242798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>StPatricksDay</td>\n",
       "      <td>0.233276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      event_name_1  mean_rss\n",
       "5      Eid al-Fitr  0.332275\n",
       "15    Mother's day  0.300049\n",
       "29     VeteransDay  0.298584\n",
       "30            none  0.291260\n",
       "20  OrthodoxEaster  0.288574\n",
       "10        LaborDay  0.258789\n",
       "6        EidAlAdha  0.256348\n",
       "16    NBAFinalsEnd  0.244995\n",
       "23       Purim End  0.242798\n",
       "25   StPatricksDay  0.233276"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_name_1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (483449040.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_1086/483449040.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <span style=\"color:blue\">Explore event_name_1 and event_type_1</span>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<span style=\"color:blue\">Explore event_name_1 and event_type_1</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ccef7bf44afae269463cc411da779302db538aea51c1c7a8159435413959511"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
