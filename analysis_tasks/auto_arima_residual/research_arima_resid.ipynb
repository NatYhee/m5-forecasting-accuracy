{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(f\"/home/npanj/personal_works/m5-forecasting-accuracy\")\n",
    "\n",
    "from src.utils.import_downcasting import import_downcasting\n",
    "from src.utils.plotting import PdfFile\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "root = os.path.join(\n",
    "    \"/home/npanj/personal_works/m5-forecasting-accuracy/assets/data/data_CA_1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wmape(data: pd.DataFrame, resid_column: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to get WMAPE\n",
    "    \"\"\"\n",
    "\n",
    "    data[\"abs_residual\"] = data[resid_column].abs()\n",
    "    sum_abs_residual = (\n",
    "        data[[\"store_id\", \"item_id\", \"abs_residual\"]]\n",
    "        .groupby([\"store_id\", \"item_id\"])\n",
    "        .abs_residual.sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "    sum_actual = (\n",
    "        data[[\"store_id\", \"item_id\", \"sales\"]]\n",
    "        .groupby([\"store_id\", \"item_id\"])\n",
    "        .sales.sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "    sum_abs_residual.rename(columns={\"abs_residual\": \"sum_abs_residual\"}, inplace=True)\n",
    "    wmape_df = pd.merge(\n",
    "        left=sum_abs_residual, right=sum_actual, on=[\"store_id\", \"item_id\"], how=\"left\"\n",
    "    )\n",
    "    wmape_df[\"wmape\"] = wmape_df[\"sum_abs_residual\"] / wmape_df[\"sales\"]\n",
    "\n",
    "    return wmape_df\n",
    "\n",
    "\n",
    "def plotting_sales_forecast(\n",
    "    data: pd.DataFrame, score: pd.DataFrame, file_name: str, product_cat: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Function to plot prediction and actual\n",
    "    \"\"\"\n",
    "\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    data_df = data.copy()\n",
    "    score_df = score.copy()\n",
    "\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "\n",
    "    if product_cat is not None:\n",
    "        data_df = data_df.loc[data_df.cat_id == product_cat]\n",
    "        score_df = score_df[score_df.item_id.isin(data_df.item_id.tolist())]\n",
    "        score_df.sort_values(by=\"wmape\", ascending=False, inplace=True)\n",
    "\n",
    "    item_ids = list(score_df.item_id.unique())\n",
    "\n",
    "    pdf = PdfFile(file_name)\n",
    "    for item_id in item_ids:\n",
    "        df = data_df.loc[data_df.item_id == item_id]\n",
    "        eval_df = score_df.loc[score_df.item_id == item_id]\n",
    "\n",
    "        store_id = str(df.store_id.unique()[0])\n",
    "        item_id = str(df.item_id.unique()[0])\n",
    "        wmape = str(eval_df.wmape.unique()[0])\n",
    "\n",
    "        title = f\"graph of store_id:{store_id} on item_id:{item_id} with WMAPE:{wmape}\"\n",
    "        pdf.save_fig(df, title)\n",
    "\n",
    "    pdf.close()\n",
    "\n",
    "\n",
    "def get_wmape_custom_groupby(data: pd.DataFrame, resid_column: str, groupby_keys: list):\n",
    "    \"\"\"\n",
    "    Function to get WMAPE wigh customize in groupby key\n",
    "    \"\"\"\n",
    "\n",
    "    data[\"abs_residual\"] = data[resid_column].abs()\n",
    "    residual_columns = copy.deepcopy(groupby_keys)\n",
    "    residual_columns.append(\"abs_residual\")\n",
    "\n",
    "    actual_columns = copy.deepcopy(groupby_keys)\n",
    "    actual_columns.append(\"sales\")\n",
    "\n",
    "    sum_abs_residual = (\n",
    "        data[residual_columns].groupby(groupby_keys).abs_residual.sum().reset_index()\n",
    "    )\n",
    "    sum_actual = data[actual_columns].groupby(groupby_keys).sales.sum().reset_index()\n",
    "    sum_abs_residual.rename(columns={\"abs_residual\": \"sum_abs_residual\"}, inplace=True)\n",
    "    wmape_df = pd.merge(\n",
    "        left=sum_abs_residual, right=sum_actual, on=groupby_keys, how=\"left\"\n",
    "    )\n",
    "    wmape_df[\"wmape\"] = wmape_df[\"sum_abs_residual\"] / wmape_df[\"sales\"]\n",
    "\n",
    "    return wmape_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ca1 = import_downcasting(os.path.join(root, \"data_with_arima_resid.csv\"))\n",
    "score_ca1 = import_downcasting(os.path.join(root, \"arima_model_score.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data ca1 list columns\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5918109 entries, 0 to 5918108\n",
      "Data columns (total 25 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   date            datetime64[ns]\n",
      " 1   id              category      \n",
      " 2   item_id         category      \n",
      " 3   dept_id         category      \n",
      " 4   cat_id          category      \n",
      " 5   store_id        category      \n",
      " 6   state_id        category      \n",
      " 7   date_code       category      \n",
      " 8   sales           int16         \n",
      " 9   wm_yr_wk        int16         \n",
      " 10  weekday         category      \n",
      " 11  wday            int8          \n",
      " 12  month           int8          \n",
      " 13  year            int16         \n",
      " 14  d               category      \n",
      " 15  event_name_1    category      \n",
      " 16  event_type_1    category      \n",
      " 17  event_name_2    category      \n",
      " 18  event_type_2    category      \n",
      " 19  snap_CA         int8          \n",
      " 20  snap_TX         int8          \n",
      " 21  snap_WI         int8          \n",
      " 22  sell_price      float16       \n",
      " 23  prediction      float16       \n",
      " 24  arima_residual  float16       \n",
      "dtypes: category(13), datetime64[ns](1), float16(3), int16(3), int8(5)\n",
      "memory usage: 237.4 MB\n",
      "None\n",
      "--------------------------------------------------\n",
      "data ca1 score list columns\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3049 entries, 0 to 3048\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   store_id  3049 non-null   category\n",
      " 1   item_id   3049 non-null   category\n",
      " 2   mse       3049 non-null   float16 \n",
      " 3   mae       3049 non-null   float16 \n",
      " 4   sse       3049 non-null   float32 \n",
      "dtypes: category(2), float16(2), float32(1)\n",
      "memory usage: 121.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"data ca1 list columns\")\n",
    "print(data_ca1.info(verbose=True))\n",
    "\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"data ca1 score list columns\")\n",
    "print(score_ca1.info())\n",
    "\n",
    "data_ca1 = data_ca1.set_index(\"date\")\n",
    "data_ca1[\"event_name_1\"] = (\n",
    "    data_ca1[\"event_name_1\"].cat.add_categories(\"none\").fillna(\"none\")\n",
    ")\n",
    "data_ca1[\"event_type_1\"] = (\n",
    "    data_ca1[\"event_type_1\"].cat.add_categories(\"none\").fillna(\"none\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmape = get_wmape(data_ca1, \"arima_residual\")\n",
    "score_ca1 = pd.merge(\n",
    "    left=score_ca1,\n",
    "    right=wmape[[\"store_id\", \"item_id\", \"wmape\"]],\n",
    "    on=[\"store_id\", \"item_id\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "score_ca1.sort_values(by=\"wmape\", ascending=False, inplace=True)\n",
    "score_ca1[\"rank_pct_wmape\"] = score_ca1[\"wmape\"].rank(pct=True)\n",
    "score_ca1 = score_ca1.reset_index(drop=True)\n",
    "\n",
    "data_ca1[\"root_square_resid\"] = data_ca1[\"arima_residual\"].apply(\n",
    "    lambda x: math.pow(x, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9147 entries, 0 to 9146\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   store_id        9147 non-null   category\n",
      " 1   item_id         9147 non-null   category\n",
      " 2   mse             9147 non-null   float16 \n",
      " 3   mae             9147 non-null   float16 \n",
      " 4   sse             9147 non-null   float32 \n",
      " 5   wmape           9147 non-null   float64 \n",
      " 6   rank_pct_wmape  9147 non-null   float64 \n",
      " 7   cat_id          9147 non-null   category\n",
      "dtypes: category(3), float16(2), float32(1), float64(2)\n",
      "memory usage: 410.2 KB\n"
     ]
    }
   ],
   "source": [
    "item_id_cat_unq = data_ca1.groupby([\"item_id\", \"cat_id\"]).store_id.count().reset_index()\n",
    "score_ca1 = pd.merge(\n",
    "    left=score_ca1,\n",
    "    right=item_id_cat_unq[[\"item_id\", \"cat_id\"]],\n",
    "    left_on=[\"item_id\"],\n",
    "    right_on=[\"item_id\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "score_ca1.info()\n",
    "##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting_sales_forecast(data=data_ca1, score=score_ca1, file_name=\"plotting_store_ca1.pdf\")\n",
    "# plotting_sales_forecast(data=data_ca1, score=score_ca1, file_name=\"plotting_hobbies_ca1.pdf\", product_cat=\"HOBBIES\")\n",
    "# plotting_sales_forecast(data=data_ca1, score=score_ca1, file_name=\"plotting_foods_ca1.pdf\", product_cat=\"FOODS\")\n",
    "# plotting_sales_forecast(data=data_ca1, score=score_ca1, file_name=\"plotting_household_ca1.pdf\",\\\n",
    "#                         product_cat=\"HOUSEHOLD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis residual from ARIMA model in the group last 20 percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_score_worst_20pct = score_ca1[score_ca1.rank_pct_wmape > 0.8]\n",
    "item_resid_worst_20pct = list(resid_score_worst_20pct.item_id.unique())\n",
    "\n",
    "data_worst_20pct = data_ca1[data_ca1.item_id.isin(item_resid_worst_20pct)]\n",
    "data_worst_20pct.to_csv(os.path.join(root, \"data_arima_worst_30pct.csv\"))\n",
    "\n",
    "data_worst_20pct = import_downcasting(os.path.join(root, \"data_arima_worst_30pct.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Explore event_name_1 and event_type_1</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding from rank in event_name_1 that \"christmas\" event tend to have the most impact on residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_name_1 = (\n",
    "    data_worst_20pct.groupby([\"event_name_1\"]).root_square_resid.mean().reset_index()\n",
    ")\n",
    "event_name_1.rename(columns={\"root_square_resid\": \"mean_rss\"}, inplace=True)\n",
    "event_name_1.sort_values(by=\"mean_rss\", ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "event_type_1 = (\n",
    "    data_worst_20pct.groupby([\"event_type_1\"]).root_square_resid.mean().reset_index()\n",
    ")\n",
    "event_type_1.rename(columns={\"root_square_resid\": \"mean_rss\"}, inplace=True)\n",
    "event_type_1.sort_values(by=\"mean_rss\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>mean_rss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Christmas</td>\n",
       "      <td>80.474136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LaborDay</td>\n",
       "      <td>35.132126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Thanksgiving</td>\n",
       "      <td>26.928791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>OrthodoxEaster</td>\n",
       "      <td>25.622793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Easter</td>\n",
       "      <td>24.203529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ColumbusDay</td>\n",
       "      <td>22.735889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Eid al-Fitr</td>\n",
       "      <td>22.226715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ramadan starts</td>\n",
       "      <td>21.743202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>none</td>\n",
       "      <td>21.446226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mother's day</td>\n",
       "      <td>21.347801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      event_name_1   mean_rss\n",
       "1        Christmas  80.474136\n",
       "10        LaborDay  35.132126\n",
       "27    Thanksgiving  26.928791\n",
       "20  OrthodoxEaster  25.622793\n",
       "4           Easter  24.203529\n",
       "3      ColumbusDay  22.735889\n",
       "5      Eid al-Fitr  22.226715\n",
       "24  Ramadan starts  21.743202\n",
       "30            none  21.446226\n",
       "15    Mother's day  21.347801"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_name_1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (483449040.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_2753/483449040.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <span style=\"color:blue\">Explore event_name_1 and event_type_1</span>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<span style=\"color:blue\">Explore event_name_1 and event_type_1</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ccef7bf44afae269463cc411da779302db538aea51c1c7a8159435413959511"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
